{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuskanBansal2001/MuskanBansal2001/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPUCo5Ai9BW7"
      },
      "source": [
        "# Check the gpu\n",
        "1.  for tiny_model, tiny_plus_model only T4 and K80 are allowed.\n",
        "2.  for big_model only P100, T4 and K80 are allowed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BQh1kwhnORp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "e185243f-c41c-4311-f23f-46087f7ffe6a"
      },
      "source": [
        "from IPython.display import HTML, clear_output\n",
        "from subprocess import getoutput\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'K80' in s:gpu = 'K80'\n",
        "elif 'T4' in s:gpu = 'T4'\n",
        "elif 'P100' in s:gpu = 'P100'\n",
        "else:gpu='DONT PROCEED'\n",
        "display(HTML(f\"<h1>{gpu}</h1>\"))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>DONT PROCEED</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dud2zCZw9Zyo"
      },
      "source": [
        "# Mount the drive and import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYaXmqidnWAU",
        "outputId": "abd47167-0e6c-4f7c-f11c-82865a39e787"
      },
      "source": [
        "from google.colab import drive\n",
        "from os import listdir, remove, makedirs\n",
        "from os.path import join, exists\n",
        "import random\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/darknet\n",
        "!chmod +x ./darknet\n",
        "!./darknet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/darknet\n",
            "usage: ./darknet <function>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFqp-YJC84kw"
      },
      "source": [
        "# Start Training from beginning\n",
        "1.  No need to run below this, if you are going to **resume**. [Click here](#resume-cell) to go to the resume cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roBSLd2qtV-x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b6e275f-ec64-4066-b191-c6d5a1e84424"
      },
      "source": [
        "# change this path\n",
        "inputpath=\"topwear_new\"\n",
        "if \"gdrive\" not in inputpath:\n",
        "    inputpath = \"/gdrive/MyDrive/\"+inputpath\n",
        "if exists(inputpath):\n",
        "    x = input(\"Which model you want to train?\\n\\t1. tiny model\\n\\t2. tiny plus model\\n\\t3. big model\\n\")\n",
        "    dont_run=False\n",
        "    if x=='1':model_type = \"tiny_model\"\n",
        "    elif x=='2':model_type = \"tiny_plus_model\"\n",
        "    elif x=='3':model_type = \"big_model\"\n",
        "    else:\n",
        "        dont_run=True\n",
        "        clear_output()\n",
        "        print(\"Enter correct input among 1,2 and 3.\")\n",
        "else:\n",
        "    print(inputpath, \"cannot be found please correct it.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Which model you want to train?\n",
            "\t1. tiny model\n",
            "\t2. tiny plus model\n",
            "\t3. big model\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ht7Pd39y8v9e"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaEF-k5mn0zc"
      },
      "source": [
        "def check_existence(folder, count=0):\n",
        "    tmp=\"\" if count==0 else \"_\"+str(count)\n",
        "    check_folder = folder+tmp\n",
        "    if (check_folder in listdir(\".\")) and (len([k for k in listdir(check_folder) if \".weights\" in k])!=0):\n",
        "        count+=1\n",
        "        return check_existence(folder, count)\n",
        "    else:\n",
        "        return check_folder\n",
        "def get_all_files(folder:str, result:dict):\n",
        "    tmp = sorted(listdir(folder))\n",
        "    result[folder]=[i for i in tmp if (\".jpg\" in i) or (\".txt\" in i)]\n",
        "    for i in tmp:\n",
        "        if \".\" not in i:\n",
        "            get_all_files(join(folder, i), result)\n",
        "def get_images_txt(folder:str):\n",
        "    data = {}\n",
        "    get_all_files(folder, data)\n",
        "    del data[folder]\n",
        "    final_data = {}\n",
        "    for i in data.keys():\n",
        "        if len(data[i])==0:\n",
        "            continue\n",
        "        class_ = i[len(folder)+1:].split(\"/\")[0]\n",
        "        if class_ not in final_data.keys():\n",
        "            final_data[class_]={}\n",
        "        final_data[class_][i] = []\n",
        "        for j in range(len(data[i])-1):\n",
        "            if data[i][j][:data[i][j].rfind('.')]==data[i][j+1][:data[i][j+1].rfind('.')]:\n",
        "                final_data[class_][i].append([i+'/'+data[i][j], i+'/'+data[i][j+1]])\n",
        "                j+=1\n",
        "    return final_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iw4ILIoq82y0"
      },
      "source": [
        "### Confirm the output folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5AE-V_GnV7T",
        "outputId": "5013425a-388a-4173-859f-52f4c91df101"
      },
      "source": [
        "if not dont_run:\n",
        "    clear_output()\n",
        "    outputpath=\"_\".join(inputpath.split(\"/\")[3:])+\"_\"+model_type\n",
        "    outputpath = check_existence(outputpath)\n",
        "    print(\"Output folder is \"+outputpath+\".\")\n",
        "    x = input(\"Please confirm to create the output folder (y/n):\")\n",
        "    if x == 'y':\n",
        "        if not exists(outputpath):\n",
        "            makedirs(outputpath)\n",
        "        print(\"Output folder created.\")\n",
        "    elif x == 'n':\n",
        "        print(\"Output folder not created.\")\n",
        "    else:\n",
        "        print(\"Please input valid character.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Output folder is topwear_new_big_model.\n",
            "Please confirm to create the output folder (y/n):y\n",
            "Output folder created.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvxq6zst9lvK"
      },
      "source": [
        "### Confirm the count of images and classes.\n",
        "1.  Those numbers tells the count of pair of image and it's annotation.\n",
        "2.  Adjust the threshold value to increase and decrease the classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwLIAJdg9jAg",
        "outputId": "c2bcbdd2-bbe2-4e1d-ad45-b69dbe5a4865"
      },
      "source": [
        "threshold = 10\n",
        "data = get_images_txt(inputpath)\n",
        "key_list = sorted(list(data.keys()))\n",
        "count=0\n",
        "for i in key_list:\n",
        "    l = sum([len(k) for k in data[i].values()])\n",
        "    if l>threshold:\n",
        "        print(count,i, l)\n",
        "        count+=1\n",
        "    else:\n",
        "        del data[i]\n",
        "x = input(\"Please confirm that classes and count of images are correct (y/n):\")\n",
        "if x == 'y':\n",
        "    classes = sorted(data.keys())\n",
        "    print(\"Classes selected.\")\n",
        "elif x == 'n':\n",
        "    classes = None\n",
        "    print(\"Classes not selected.\")\n",
        "else:\n",
        "    classes = None\n",
        "    print(\"Please input valid character.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 brassiere 692\n",
            "1 shirts 2182\n",
            "2 sweatshirt 1137\n",
            "3 tops 5851\n",
            "Please confirm that classes and count of images are correct (y/n):y\n",
            "Classes selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGYShOHUDwki"
      },
      "source": [
        "def clip_first(n, d):\n",
        "    key_list = sorted(list(d.keys()))\n",
        "    result = {i:[] for i in key_list}\n",
        "    key_counter = {i:0 for i in key_list}\n",
        "    prev = 0\n",
        "    while True:\n",
        "        for i in key_list:\n",
        "            if key_counter[i]>=len(d[i]):\n",
        "                continue\n",
        "            else:\n",
        "                result[i].append(d[i][key_counter[i]])\n",
        "                key_counter[i]+=1\n",
        "        x = sum([len(k) for k in result.values()])\n",
        "        if x==prev:\n",
        "            break\n",
        "        prev = x\n",
        "        if sum([len(k) for k in result.values()])>=n:\n",
        "            break\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwSjd-66Cyo7",
        "outputId": "d315b190-c714-40d8-fdb7-3e7f91c3358c"
      },
      "source": [
        "key_list = sorted(list(data.keys()))\n",
        "min_count=100000000\n",
        "for i in key_list:\n",
        "    l = sum([len(k) for k in data[i].values()])\n",
        "    min_count = min(min_count, l)\n",
        "print(\"Minimum number of images in a class:\",min_count)\n",
        "for i in key_list:\n",
        "    data[i] = clip_first(min_count, data[i])\n",
        "count = 0\n",
        "for i in key_list:\n",
        "    l = sum([len(k) for k in data[i].values()])\n",
        "    print(count, i, l)\n",
        "    count+=1\n",
        "x = input(\"Please confirm that clipped count of images are correct (y/n):\")\n",
        "if x == 'y':\n",
        "    classes = sorted(data.keys())\n",
        "    print(\"Classes selected.\")\n",
        "elif x == 'n':\n",
        "    classes = None\n",
        "    print(\"Classes not selected.\")\n",
        "else:\n",
        "    classes = None\n",
        "    print(\"Please input valid character.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Minimum number of images in a class: 692\n",
            "0 brassiere 692\n",
            "1 shirts 692\n",
            "2 sweatshirt 692\n",
            "3 tops 692\n",
            "Please confirm that clipped count of images are correct (y/n):y\n",
            "Classes selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6mRoTJQ6EdB",
        "outputId": "afd423ed-0766-452c-a61b-cefefb1f41ba"
      },
      "source": [
        "for i in classes:\n",
        "    print(i)\n",
        "    for j in sorted(data[i].keys()):\n",
        "        print(j, len(data[i][j]))\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "brassiere\n",
            "/gdrive/MyDrive/topwear_new/brassiere 692\n",
            "\n",
            "shirts\n",
            "/gdrive/MyDrive/topwear_new/shirts 692\n",
            "\n",
            "sweatshirt\n",
            "/gdrive/MyDrive/topwear_new/sweatshirt 692\n",
            "\n",
            "tops\n",
            "/gdrive/MyDrive/topwear_new/tops 692\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2rrtGHB-B4L"
      },
      "source": [
        "### Change ids in the annotation files\n",
        "1.  This cell will take some time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "jaHwsx4DyZjC",
        "outputId": "b52bbc00-f539-4a74-99b3-5e1828acf74f"
      },
      "source": [
        "for id in range(len(classes)):\n",
        "    tmp = 0\n",
        "    cls = classes[id]\n",
        "    print(cls+\"-\", end = \" \")\n",
        "    for i in data[cls].keys():\n",
        "        for j in data[cls][i]:\n",
        "            f = open(j[1],'r')\n",
        "            s = [k.split(\" \") for k in f.read().split('\\n')]\n",
        "            s = [k for k in s if len(k)==5]\n",
        "            s = [[str(id)]+k[1:] for k in s]\n",
        "            s = \"\\n\".join([\" \".join(k) for k in s])+\"\\n\"\n",
        "            f.close()\n",
        "            f = open(j[1],'w')\n",
        "            f.write(s)\n",
        "            f.close()\n",
        "            tmp+=1\n",
        "            if tmp%100==0:\n",
        "                print(tmp, end=\".. \")\n",
        "    print(tmp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "brassiere- 100.. 200.. 300.. 400.. 500.. 600.. "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-9203279af3e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z7EPmxuX-TLs"
      },
      "source": [
        "### Save the training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_FJLnSRNhNp"
      },
      "source": [
        "train=[]\n",
        "for id in range(len(classes)):\n",
        "    for i in data[classes[id]].keys():\n",
        "        train.extend([k[0] for k in data[classes[id]][i]])\n",
        "train=[i for i in train if \".txt\" not in i]\n",
        "random.shuffle(train)\n",
        "l=len(train)\n",
        "valid=train[int(l*5/6):]\n",
        "train=train[:int(l*5/6)]\n",
        "f=open(join(outputpath, model_type+\"_train.txt\"),'w')\n",
        "f.write(\"\\n\".join(train))\n",
        "f.close()\n",
        "f=open(join(outputpath, model_type+\"_valid.txt\"),'w')\n",
        "f.write(\"\\n\".join(valid))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U7KgmqIF-dbQ"
      },
      "source": [
        "### Save the names file and data file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1qZlwAZKeW-"
      },
      "source": [
        "f=open(join(outputpath, model_type+\"_obj.names\"),'w')\n",
        "f.write(\"\\n\".join(classes))\n",
        "f.close()\n",
        "numClass=len(classes)\n",
        "objdata=[\"classes= \"+str(numClass),\n",
        "         \"train = \"+join(outputpath, model_type+\"_train.txt\"),\n",
        "         \"valid = \"+join(outputpath, model_type+\"_valid.txt\"),\n",
        "         \"names = \"+join(outputpath, model_type+\"_obj.names\"),\n",
        "         \"backup = \"+outputpath+\"/\"]\n",
        "f=open(join(outputpath, model_type+\"_obj.data\"),\"w\")\n",
        "f.write(\"\\n\".join(objdata))\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhxyQi-n-joS"
      },
      "source": [
        "### Copy the appropriate config file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF96JCwrM5wK"
      },
      "source": [
        "import shutil\n",
        "dest_cfg_name = model_type+\"_yolov4.cfg\"\n",
        "if model_type == \"tiny_model\":\n",
        "    src_cfg_name = \"yolov4-tiny-custom.cfg\"\n",
        "    netSize=416\n",
        "    batch=64\n",
        "    subdiv=1\n",
        "    max_batches_multiplier = 3000\n",
        "    default_max_batch = 500200\n",
        "elif model_type == \"tiny_plus_model\":\n",
        "    src_cfg_name = \"yolov4-tiny-custom.cfg\"\n",
        "    netSize=608\n",
        "    batch=64\n",
        "    subdiv=2\n",
        "    max_batches_multiplier = 3000\n",
        "    default_max_batch = 500200\n",
        "elif model_type == \"big_model\":\n",
        "    src_cfg_name = \"yolov4-custom.cfg\"\n",
        "    netSize=416\n",
        "    batch=64\n",
        "    subdiv=16\n",
        "    max_batches_multiplier = 2000\n",
        "    default_max_batch = 500500\n",
        "if dest_cfg_name not in listdir(outputpath):\n",
        "    shutil.copy(\"cfg/\"+src_cfg_name, outputpath+'/'+dest_cfg_name)\n",
        "else:\n",
        "    remove(outputpath+'/'+dest_cfg_name)\n",
        "    shutil.copy(\"cfg/\"+src_cfg_name, outputpath+'/'+dest_cfg_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AopuOjN6-rqQ"
      },
      "source": [
        "### Configure the training details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2l9Q1CpNx4C"
      },
      "source": [
        "#change number of class and filters\n",
        "comm='s/classes=80/classes='+str(numClass)+\"/\"\n",
        "!sed -i $comm $outputpath/$dest_cfg_name\n",
        "comm='s/filters=255/filters='+str((numClass+5)*3)+\"/\"\n",
        "!sed -i $comm $outputpath/$dest_cfg_name\n",
        "\n",
        "#change number of steps and max batches\n",
        "max_batches=max(6000,(numClass)*max_batches_multiplier)\n",
        "comm='s/max_batches\\ =\\ '+str(default_max_batch)+'/max_batches\\ =\\ '+str(max_batches)+\"/\"\n",
        "!sed -i $comm $outputpath/$dest_cfg_name\n",
        "comm='s/steps=400000,450000/steps='+str(int(0.8*max_batches))+','+str(int(0.9*max_batches))+\"/\"\n",
        "!sed -i $comm $outputpath/$dest_cfg_name\n",
        "\n",
        "#can be multiple of 32 or 608(but makes training slow)\n",
        "comm='s/width=416/width='+str(netSize)+\"/\"\n",
        "!sed -i $comm $outputpath/$dest_cfg_name\n",
        "comm='s/height=416/height='+str(netSize)+\"/\"\n",
        "!sed -i $comm $outputpath/$dest_cfg_name\n",
        "\n",
        "comm='s/batch=64/batch='+str(batch)+'/'\n",
        "!sed -i $comm $outputpath/$dest_cfg_name\n",
        "comm='s/subdivisions=1/subdivisions='+str(subdiv)+'/'\n",
        "!sed -i $comm $outputpath/$dest_cfg_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83JHL5EF-yEM"
      },
      "source": [
        "### Download the weight if doesn't exist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCvbe5TbSU9t"
      },
      "source": [
        "if \"yolov4.conv.137\" not in listdir():\n",
        "    !wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.conv.137\n",
        "if \"yolov4-tiny.conv.29\" not in listdir():\n",
        "    !wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v4_pre/yolov4-tiny.conv.29"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz3PJ-Lc-4zN"
      },
      "source": [
        "# Start the training\n",
        "1.  if you are running from the top, then run the below cell directly.\n",
        "2.  if you have done the configurations before hand, and want to run this cell, then define the outputpath variable in some other cell, and then run the below cell.\n",
        "3.  outputpath variable contains the folder name in which model will be saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN2e7-UIS5zy",
        "outputId": "40dcb817-eaee-4386-cf96-561619be6704",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "obj_file = None\n",
        "cfg_file = None\n",
        "\n",
        "if \"tiny_model\" in outputpath : model_name = \"yolov4-tiny.conv.29\"\n",
        "elif \"tiny_plus_model\" in outputpath : model_name = \"yolov4-tiny.conv.29\"\n",
        "elif \"big_model\" in outputpath : model_name = \"yolov4.conv.137\"\n",
        "\n",
        "for i in listdir(outputpath):\n",
        "    if \"obj.data\" in i:\n",
        "        obj_file = join(outputpath, i)\n",
        "    elif \".cfg\" in i:\n",
        "        cfg_file = join(outputpath, i)\n",
        "\n",
        "if obj_file == None:\n",
        "    print(\".data file not found in\", outputpath)\n",
        "\n",
        "if cfg_file ==None:\n",
        "    print(\".cfg file not found in\", outputpath)\n",
        "\n",
        "if (obj_file != None) and (cfg_file != None):\n",
        "    !./darknet detector train $obj_file $cfg_file $model_name -dont_show -map"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ea81ad1738d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0;34m\"big_model\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputpath\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"yolov4.conv.137\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"obj.data\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mobj_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'listdir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvQicrPx_pDW"
      },
      "source": [
        "<a name=\"resume-cell\"></a>\n",
        "# Resume the training\n",
        "1. For resuming the training process, it is complulsory to define the outputpath.\n",
        "2.  outputpath variable contains the folder name in which model will be saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "XNyTNjp6UNvn",
        "outputId": "c122c899-2eb9-40eb-91a2-d78ae58800e9"
      },
      "source": [
        "outputpath = input(\"Write the outputpath where previous training was done?\\n\")\n",
        "clear_output()\n",
        "\n",
        "obj_file = None\n",
        "cfg_file = None\n",
        "last_weight = None\n",
        "folder_exists = exists(outputpath)\n",
        "if folder_exists:\n",
        "    for i in listdir(outputpath):\n",
        "        if \"obj.data\" in i:\n",
        "            obj_file = join(outputpath, i)\n",
        "        elif \".cfg\" in i:\n",
        "            cfg_file = join(outputpath, i)\n",
        "        elif \"last.weights\" in i:\n",
        "            last_weight = join(outputpath, i)\n",
        "else:\n",
        "    print(outputpath, \"does not exist please check the name.\")\n",
        "\n",
        "if (obj_file == None) and (folder_exists):\n",
        "    print(\".data file not found in\", outputpath)\n",
        "if (cfg_file ==None) and (folder_exists):\n",
        "    print(\".cfg file not found in\", outputpath)\n",
        "if (last_weight ==None) and (folder_exists):\n",
        "    print(\"last.weights file not found in\", outputpath)\n",
        "\n",
        "if (obj_file != None) and (cfg_file != None) and (last_weight != None):\n",
        "    !./darknet detector train $obj_file $cfg_file $last_weight -dont_show -map"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write the outputpath where previous training was done?\n",
            "footwear_ballerinas_tiny_plus_model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-098af8b3c002>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moutputpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Write the outputpath where previous training was done?\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mobj_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcfg_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'clear_output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNz5Yx2dWqJT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}