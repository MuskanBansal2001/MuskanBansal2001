{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tagging of Products.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuskanBansal2001/MuskanBansal2001/blob/main/Tagging_of_Products.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPUCo5Ai9BW7"
      },
      "source": [
        "# Check the gpu\n",
        "P100 > T4 > P4 > K80"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BQh1kwhnORp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "51e8f1c2-9a57-4ecd-ad89-44302944753c"
      },
      "source": [
        "from IPython.display import HTML, clear_output\n",
        "from subprocess import getoutput\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'K80' in s:gpu = 'K80'\n",
        "elif 'T4' in s:gpu = 'T4'\n",
        "elif 'P100' in s:gpu = 'P100'\n",
        "elif 'P4' in s:gpu = 'P4'\n",
        "display(HTML(f\"<h1>{gpu}</h1>\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h1>K80</h1>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6sn-SvmqXQL",
        "outputId": "38d1c6c6-af25-4a2f-fd8d-0530bc6ed309"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive/MyDrive/experiment2/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n",
            "/gdrive/MyDrive/experiment2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVloTLEKqeDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9641b6-9392-48b3-cf7c-77d22f38108a"
      },
      "source": [
        "!pip install -q yolov4==2.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for yolov4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSB4WtvsqgD0",
        "outputId": "4179325e-c24c-4609-83d4-054484a6033e"
      },
      "source": [
        "from os.path import join, exists\n",
        "from os import listdir\n",
        "import json\n",
        "\n",
        "\n",
        "from global_vars import *\n",
        "from helpers import load_image_from_link, load_image_from_path\n",
        "from model import load_normal_models, load_2ndlvl_models\n",
        "from inference_helpers import *\n",
        "\n",
        "from primary_image_detector import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Call tf.config.experimental.set_memory_growth(GPU0, True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ko5xp5XDxdyc"
      },
      "source": [
        "## Load Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrUg3I4VqvxN"
      },
      "source": [
        "posenet_model = load_posenet_model()\n",
        "\n",
        "topwear_models=load_normal_models(topwear)\n",
        "\n",
        "outerwear_models=load_normal_models(outerwear)\n",
        "outerwear_models[\"sub\"][\"edge_type\"]=topwear_models[\"sub\"][\"edge_type\"]\n",
        "\n",
        "bottomwear_models=load_normal_models(bottomwear)\n",
        "\n",
        "footwear_models=load_normal_models(footwear)\n",
        "\n",
        "overall_models=load_normal_models(overall)\n",
        "\n",
        "accessories_models=load_normal_models(accessories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hy7Pn0SXBP1"
      },
      "source": [
        "topwear_nonhuman = \"topwear_nonhuman\"\n",
        "topwear_nonhuman_model = load_normal_models(topwear_nonhuman)\n",
        "\n",
        "bottomwear_nonhuman = \"bottomwear_nonhuman\"\n",
        "bottomwear_nonhuman_model = load_normal_models(bottomwear_nonhuman)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzIfeC3rXEFL"
      },
      "source": [
        "# img = load_image_from_link(\"https://i.ebayimg.com/images/g/xRYAAOSw~oFXGnNz/s-l400.jpg\")\n",
        "from primary_image_detector import predict_pose\n",
        "def hasHuman(img, posenet_model):\n",
        "    lst, image, disp = predict_pose(img, posenet_model)\n",
        "    lst = sorted(lst, key = lambda x:x[2], reverse=True)\n",
        "    if (lst[0][2]>0.5) and (lst[1][2]>0.5):\n",
        "        # print(lst)\n",
        "        return True\n",
        "    else:\n",
        "        # print(lst)\n",
        "        return False\n",
        "# hasHuman(img, posenet_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkmXWVRnnKX5"
      },
      "source": [
        "from PIL.Image import fromarray as fa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbfuEXlcodFu"
      },
      "source": [
        "topwear_main_model_conf = 0.04\n",
        "topwear_nonhuman_main_model_conf = 0.04\n",
        "bottomwear_main_model_conf = 0.2\n",
        "bottomwear_nonhuman_main_model_conf = 0.2\n",
        "accessories_main_model_conf = 0.2\n",
        "footwear_main_model_conf = 0.2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pm7HxjmrZr9"
      },
      "source": [
        "def predict(url, found = None):\n",
        "\n",
        "    # Image downloading and finding primary image if required\n",
        "    if type(url) == list:\n",
        "        img_list = []\n",
        "        for i in url:\n",
        "            if type(i)!=str:\n",
        "                raise Exception(\"Urls list should contain only string type elements.\")\n",
        "            img_list.append(load_image_from_link(i))\n",
        "        ind = find_primary(img_list, posenet_model)\n",
        "        image_link = url[ind]\n",
        "        img = img_list[ind]\n",
        "    elif type(url) == str:\n",
        "        image_link = url\n",
        "        img = load_image_from_link(url)\n",
        "    else:\n",
        "        raise Exception(\"Url parameter should be string type or a list of string type.\")\n",
        "    #check if it has human or not\n",
        "    # hash = hasHuman(img, posenet_model)\n",
        "    # print(hash)\n",
        "    hash = True\n",
        "\n",
        "    # initialising all the variables\n",
        "    topwear_detection = []\n",
        "    bottomwear_detection = []\n",
        "    accessories_sub_detection = {}\n",
        "    footwear_detection = []\n",
        "\n",
        "    bottomwear_sub_detection={}\n",
        "    topwear_sub_detection={}\n",
        "    overall_sub_detection={}\n",
        "    outerwear_sub_detection={}\n",
        "\n",
        "    # resolving the already known thing\n",
        "    if not hash:\n",
        "        if found == None:\n",
        "            topwear_detection, topwear_color = topwear_nonhuman_model[\"main\"].predict(img, 0.1, topwear_nonhuman_main_model_conf)\n",
        "            bottomwear_detection, bottomwear_color = bottomwear_nonhuman_model[\"main\"].predict(img, 0.1, bottomwear_nonhuman_main_model_conf)\n",
        "            accessories_sub_detection = accessories_prediction(img, accessories_models['main'], ren, 0.1, accessories_main_model_conf)\n",
        "            footwear_detection, footwear_color = footwear_models[\"main\"].predict(img, 0.1, footwear_main_model_conf)\n",
        "        elif found in topwear_models[\"main\"].class_dict.values():\n",
        "            topwear_detection = [[found, 1]]\n",
        "        elif found == topwear:\n",
        "            topwear_detection, topwear_color = topwear_nonhuman_model[\"main\"].predict(img, 0.1, topwear_nonhuman_main_model_conf)\n",
        "        elif found in bottomwear_models[\"main\"].class_dict.values():\n",
        "            bottomwear_detection = [[found, 1]]\n",
        "        elif found == bottomwear:\n",
        "            bottomwear_detection, bottomwear_color = bottomwear_nonhuman_model[\"main\"].predict(img, 0.1, bottomwear_nonhuman_main_model_conf)\n",
        "        elif (found == accessories) or (found in accessories_models[\"main\"].class_dict.values()):\n",
        "            accessories_sub_detection = accessories_prediction(img, accessories_models['main'], ren, 0.1, accessories_main_model_conf)\n",
        "        elif (found == footwear) or (found in footwear_models[\"main\"].class_dict.values()):\n",
        "            footwear_detection, footwear_color = footwear_models[\"main\"].predict(img, 0.1, footwear_main_model_conf)\n",
        "        else:\n",
        "            raise Exception(found+\" not found in any model.\")\n",
        "    else:\n",
        "        if found == None:\n",
        "            topwear_detection, topwear_color = topwear_models[\"main\"].predict(img, 0.1, topwear_main_model_conf)\n",
        "            bottomwear_detection, bottomwear_color = bottomwear_models[\"main\"].predict(img, 0.1, bottomwear_main_model_conf)\n",
        "            accessories_sub_detection = accessories_prediction(img, accessories_models['main'], ren, 0.1, accessories_main_model_conf)\n",
        "            footwear_detection, footwear_color = footwear_models[\"main\"].predict(img, 0.1, footwear_main_model_conf)\n",
        "        elif found in topwear_models[\"main\"].class_dict.values():\n",
        "            topwear_detection = [[found, 1]]\n",
        "        elif found == topwear:\n",
        "            topwear_detection, topwear_color = topwear_models[\"main\"].predict(img, 0.1, topwear_main_model_conf)\n",
        "        elif found in bottomwear_models[\"main\"].class_dict.values():\n",
        "            bottomwear_detection = [[found, 1]]\n",
        "        elif found == bottomwear:\n",
        "            bottomwear_detection, bottomwear_color = bottomwear_models[\"main\"].predict(img, 0.1, bottomwear_main_model_conf)\n",
        "        elif (found == accessories) or (found in accessories_models[\"main\"].class_dict.values()):\n",
        "            accessories_sub_detection = accessories_prediction(img, accessories_models['main'], ren, 0.1, accessories_main_model_conf)\n",
        "        elif (found == footwear) or (found in footwear_models[\"main\"].class_dict.values()):\n",
        "            footwear_detection, footwear_color = footwear_models[\"main\"].predict(img, 0.1, footwear_main_model_conf)\n",
        "        else:\n",
        "            raise Exception(found+\" not found in any model.\")\n",
        "\n",
        "    # making further predictions\n",
        "    if len(topwear_detection)!=0:\n",
        "        topwear_detection = [topwear_detection[0]]\n",
        "        if topwear_detection[0][0] in ['bodysuit', 'jumpsuit', 'kaftan', 'dress']:\n",
        "            if (len(bottomwear_detection)==0) or (topwear_detection[0][1]>bottomwear_detection[0][1]):\n",
        "                overall_sub_detection = sub_model_prediction(img, topwear_detection, overall_models['sub'], 0.1, 0.1)\n",
        "            else:topwear_detection = []\n",
        "        elif topwear_detection[0][0] in ['blazers', 'cardigan', 'coat', 'jacket']:\n",
        "            outerwear_sub_detection = sub_model_prediction(img, topwear_detection, outerwear_models['sub'], 0.1, 0.1)\n",
        "        else:\n",
        "            topwear_sub_detection = sub_model_prediction(img, topwear_detection, topwear_models['sub'], 0.1, 0.1)\n",
        "\n",
        "    bottomwear_sub_detection = sub_model_prediction(img, bottomwear_detection, bottomwear_models['sub'], 0.1, 0.1)\n",
        "\n",
        "    footwear_sub_detection = sub_model_prediction(img, footwear_detection, footwear_models['sub'], 0.1, 0.1)\n",
        "    if len(footwear_detection)!=0:\n",
        "        footwear_sub_detection['color']=transform_color(footwear_color)\n",
        "\n",
        "    # transforming results\n",
        "    trans_result = transform_result({\n",
        "                    topwear:topwear_sub_detection,\n",
        "                    bottomwear:bottomwear_sub_detection,\n",
        "                    overall:overall_sub_detection,\n",
        "                    outerwear:outerwear_sub_detection,\n",
        "                    footwear:footwear_sub_detection,\n",
        "                    accessories:accessories_sub_detection\n",
        "                },ren)\n",
        "    trans_result[\"found_primary\"] = image_link\n",
        "    return trans_result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU0n7BoXfPy7"
      },
      "source": [
        "f=open(\"rename.json\", \"r\")\n",
        "ren = json.load(f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEfygzs_lIr_"
      },
      "source": [
        "# url = \"https://images.unsplash.com/photo-1563389234808-52344934935c?ixid=MnwxMjA3fDB8MHxzZWFyY2h8OXx8c2hpcnR8ZW58MHx8MHx8&ixlib=rb-1.2.1&w=1000&q=80\"\n",
        "# # url = \"https://imagesvc.meredithcorp.io/v3/mm/image?url=https%3A%2F%2Fstatic.onecms.io%2Fwp-content%2Fuploads%2Fsites%2F14%2F2019%2F04%2F09%2F040919-sexy-cardigan-lead-2000.jpg&q=85\"\n",
        "# # url = \"https://cdn.shopify.com/s/files/1/0915/5382/products/KK2447_Casey_Longline_Cardigan_Black_01_1024x1024@3x.jpg\"\n",
        "# print(json.dumps(predict(url), indent=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGNtZPhQ-Lsb"
      },
      "source": [
        "import json\n",
        "from multiprocess import Pool as ThreadPool\n",
        "import requests\n",
        "import time\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6u8tL61Cume"
      },
      "source": [
        "f = open(\"grroomTagging/productRename_2.json\", \"r\")\n",
        "productRename = json.load(f)\n",
        "f.close()\n",
        "dont_need_to_run = []\n",
        "need_to_run = []\n",
        "for i,j in productRename.items():\n",
        "    if j==None:\n",
        "        dont_need_to_run.append(i)\n",
        "    else:\n",
        "        need_to_run.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1_AqOyKC_Ix"
      },
      "source": [
        "def prep_payload(d):\n",
        "    present = productRename[d[\"productCategory\"]]\n",
        "    if present in [\"topwear\",\"blazers\",\"bodysuit\",\"brasserie\",\"cardigan\",\"coat\",\"dress\",\"jacket\",\"jumpsuit\",\"kaftan\",\"poncho\",\"shirts\",\"sweatshirt\",\"tops\",\"bottomwear\",\"culottes\",\"jeans\",\"leggings\",\"shorts\",\"skirt\",\"sweatpant\",\"trouser\",\"underpants\"]:\n",
        "        url = d[\"secondaryImageLinks\"]\n",
        "        url.append(d['primaryImageLink'])\n",
        "    else:\n",
        "        url = d[\"primaryImageLink\"]\n",
        "    return [url, present]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJ-tFOhKD6fa",
        "outputId": "bc795a36-aafc-42f0-b6f2-72f2a40f17d2"
      },
      "source": [
        "target_file = input(\"Enter name of the file (Ex: Myntra_Iteration_1_1.json):\\n\")\n",
        "if target_file in listdir(\"grroomTagging/raw\"):\n",
        "    f = open(\"grroomTagging/raw/\"+target_file, \"r\")\n",
        "    tmp = json.load(f)\n",
        "    f.close()\n",
        "    if target_file in listdir(\"grroomTagging/processed\"):\n",
        "        resp = input(\"Part of the file is already processed, want to resume (y/n)\")\n",
        "        if resp==\"n\":pass\n",
        "        elif resp ==\"y\":\n",
        "            f = open(\"grroomTagging/processed/\"+target_file, \"r\")\n",
        "            proc = json.load(f)\n",
        "            proc_id = [i[\"_id\"] for i in proc]\n",
        "            f.close()\n",
        "            raw_data = []\n",
        "            for i in tmp:\n",
        "                if i[\"_id\"] not in proc_id:\n",
        "                    raw_data.append(i)\n",
        "            print(\"Total products selected:\", len(raw_data))\n",
        "        else:\n",
        "            print(\"Response should be either 'y' or 'n'!\")\n",
        "    else:\n",
        "        raw_data = tmp\n",
        "        proc = []\n",
        "        print(\"Total products selected:\", len(raw_data))\n",
        "else:\n",
        "    print(\"Some error in the file name, please correct it.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter name of the file (Ex: Myntra_Iteration_1_1.json):\n",
            "Metroshoes_Iteration_2_1.json\n",
            "Total products selected: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsFz2rjmEKxN",
        "outputId": "7197aded-3afd-475a-9591-8dc82b70a71f"
      },
      "source": [
        "total_products = len(raw_data)\n",
        "start = time.time()\n",
        "gender_dict = {\n",
        "    \"Men\":\"Male\",\n",
        "    \"Women\":\"Female\",\n",
        "    \"Unisex\":\"Others\"\n",
        "}\n",
        "for i in range(total_products):\n",
        "    avgTime = round((time.time()-start)/(i+1), 1)\n",
        "    etc = round(avgTime*(total_products-i)/60, 1)\n",
        "    te = round((time.time()-start)/60, 1)\n",
        "    status = \"\\n{}/{}, AvgTime:{}, ETC {} mints, TimeElapsed: {} mints\".format(i, total_products, avgTime, etc, te)\n",
        "    sys.stdout.write(status)\n",
        "    url, present = prep_payload(raw_data[i])\n",
        "    try:\n",
        "        data = predict(url, present)\n",
        "        data = {**data, **raw_data[i]}\n",
        "        data[\"gender\"] = gender_dict[data[\"gender\"]]\n",
        "        proc.append(data)\n",
        "        if len(proc)%100==0:\n",
        "            f=open(\"grroomTagging/processed/\"+target_file, \"w\")\n",
        "            json.dump(proc, f)\n",
        "            f.close()\n",
        "        sys.stdout.write(\"\\b\" * (len(status)))\n",
        "    except KeyboardInterrupt:\n",
        "        break\n",
        "    except:\n",
        "      print(url)\n",
        "      continue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0/74, AvgTime:0.0, ETC 0.0 mints, TimeElapsed: 0.0 mintsWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f020e656440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "1/74, AvgTime:4.8, ETC 5.8 mints, TimeElapsed: 0.2 mintsWARNING:tensorflow:6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f020e489830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "2/74, AvgTime:8.2, ETC 9.8 mints, TimeElapsed: 0.4 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "3/74, AvgTime:9.4, ETC 11.1 mints, TimeElapsed: 0.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "4/74, AvgTime:9.2, ETC 10.7 mints, TimeElapsed: 0.8 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "5/74, AvgTime:10.3, ETC 11.8 mints, TimeElapsed: 1.0 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "6/74, AvgTime:10.6, ETC 12.0 mints, TimeElapsed: 1.2 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "7/74, AvgTime:12.3, ETC 13.7 mints, TimeElapsed: 1.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "8/74, AvgTime:12.7, ETC 14.0 mints, TimeElapsed: 1.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "9/74, AvgTime:13.0, ETC 14.1 mints, TimeElapsed: 2.2 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "10/74, AvgTime:12.9, ETC 13.8 mints, TimeElapsed: 2.4 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "11/74, AvgTime:12.5, ETC 13.1 mints, TimeElapsed: 2.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "12/74, AvgTime:13.1, ETC 13.5 mints, TimeElapsed: 2.8 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "13/74, AvgTime:12.7, ETC 12.9 mints, TimeElapsed: 3.0 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "14/74, AvgTime:12.6, ETC 12.6 mints, TimeElapsed: 3.2 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "15/74, AvgTime:12.6, ETC 12.4 mints, TimeElapsed: 3.4 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "16/74, AvgTime:12.4, ETC 12.0 mints, TimeElapsed: 3.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "17/74, AvgTime:12.0, ETC 11.4 mints, TimeElapsed: 3.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "18/74, AvgTime:12.3, ETC 11.5 mints, TimeElapsed: 3.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "19/74, AvgTime:12.2, ETC 11.2 mints, TimeElapsed: 4.1 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "20/74, AvgTime:12.4, ETC 11.2 mints, TimeElapsed: 4.3 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "21/74, AvgTime:12.3, ETC 10.9 mints, TimeElapsed: 4.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "22/74, AvgTime:12.5, ETC 10.8 mints, TimeElapsed: 4.8 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "23/74, AvgTime:12.8, ETC 10.9 mints, TimeElapsed: 5.1 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "24/74, AvgTime:12.9, ETC 10.8 mints, TimeElapsed: 5.4 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "25/74, AvgTime:13.2, ETC 10.8 mints, TimeElapsed: 5.7 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "26/74, AvgTime:13.1, ETC 10.5 mints, TimeElapsed: 5.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "27/74, AvgTime:13.1, ETC 10.3 mints, TimeElapsed: 6.1 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "28/74, AvgTime:13.7, ETC 10.5 mints, TimeElapsed: 6.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "29/74, AvgTime:13.3, ETC 10.0 mints, TimeElapsed: 6.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "30/74, AvgTime:13.2, ETC 9.7 mints, TimeElapsed: 6.8 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "31/74, AvgTime:12.9, ETC 9.2 mints, TimeElapsed: 6.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "32/74, AvgTime:12.9, ETC 9.0 mints, TimeElapsed: 7.1 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "33/74, AvgTime:12.8, ETC 8.7 mints, TimeElapsed: 7.3 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "34/74, AvgTime:13.0, ETC 8.7 mints, TimeElapsed: 7.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "35/74, AvgTime:12.9, ETC 8.4 mints, TimeElapsed: 7.8 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "36/74, AvgTime:12.8, ETC 8.1 mints, TimeElapsed: 7.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "37/74, AvgTime:12.6, ETC 7.8 mints, TimeElapsed: 8.0 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "38/74, AvgTime:12.6, ETC 7.6 mints, TimeElapsed: 8.2 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "39/74, AvgTime:12.4, ETC 7.2 mints, TimeElapsed: 8.3 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "40/74, AvgTime:12.4, ETC 7.0 mints, TimeElapsed: 8.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "41/74, AvgTime:12.3, ETC 6.8 mints, TimeElapsed: 8.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "42/74, AvgTime:12.1, ETC 6.5 mints, TimeElapsed: 8.7 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "43/74, AvgTime:12.0, ETC 6.2 mints, TimeElapsed: 8.8 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "44/74, AvgTime:12.3, ETC 6.2 mints, TimeElapsed: 9.3 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "45/74, AvgTime:12.2, ETC 5.9 mints, TimeElapsed: 9.4 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "46/74, AvgTime:12.1, ETC 5.6 mints, TimeElapsed: 9.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "47/74, AvgTime:12.4, ETC 5.6 mints, TimeElapsed: 9.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "48/74, AvgTime:12.3, ETC 5.3 mints, TimeElapsed: 10.1 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "49/74, AvgTime:12.2, ETC 5.1 mints, TimeElapsed: 10.2 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "50/74, AvgTime:12.3, ETC 4.9 mints, TimeElapsed: 10.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "51/74, AvgTime:12.2, ETC 4.7 mints, TimeElapsed: 10.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "52/74, AvgTime:12.0, ETC 4.4 mints, TimeElapsed: 10.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "53/74, AvgTime:12.1, ETC 4.2 mints, TimeElapsed: 10.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "54/74, AvgTime:12.0, ETC 4.0 mints, TimeElapsed: 11.0 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "55/74, AvgTime:12.1, ETC 3.8 mints, TimeElapsed: 11.3 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "56/74, AvgTime:12.1, ETC 3.6 mints, TimeElapsed: 11.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "57/74, AvgTime:12.1, ETC 3.4 mints, TimeElapsed: 11.7 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "58/74, AvgTime:12.0, ETC 3.2 mints, TimeElapsed: 11.8 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "59/74, AvgTime:11.9, ETC 3.0 mints, TimeElapsed: 11.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "60/74, AvgTime:11.8, ETC 2.8 mints, TimeElapsed: 12.0 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "61/74, AvgTime:11.8, ETC 2.6 mints, TimeElapsed: 12.2 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "62/74, AvgTime:11.8, ETC 2.4 mints, TimeElapsed: 12.4 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "63/74, AvgTime:11.8, ETC 2.2 mints, TimeElapsed: 12.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "64/74, AvgTime:11.8, ETC 2.0 mints, TimeElapsed: 12.8 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "65/74, AvgTime:11.7, ETC 1.8 mints, TimeElapsed: 12.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "66/74, AvgTime:11.7, ETC 1.6 mints, TimeElapsed: 13.0 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "67/74, AvgTime:11.7, ETC 1.4 mints, TimeElapsed: 13.3 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "68/74, AvgTime:11.8, ETC 1.2 mints, TimeElapsed: 13.5 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "69/74, AvgTime:11.7, ETC 1.0 mints, TimeElapsed: 13.6 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "70/74, AvgTime:11.6, ETC 0.8 mints, TimeElapsed: 13.7 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "71/74, AvgTime:11.6, ETC 0.6 mints, TimeElapsed: 13.9 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "72/74, AvgTime:11.6, ETC 0.4 mints, TimeElapsed: 14.2 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
            "73/74, AvgTime:11.6, ETC 0.2 mints, TimeElapsed: 14.3 mints\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAUBBQxdhzoD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}